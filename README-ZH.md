<div align="center">
<a href="https://github.com/Evil0ctal/Fast-Powerful-Whisper-AI-Services-API" alt="logo" ><img src="https://raw.githubusercontent.com/Evil0ctal/Fast-Powerful-Whisper-AI-Services-API/refs/heads/main/github/logo/logo.jpg" width="150"/></a>
</div>
<h1 align="center">Fast-Powerful-Whisper-AI-Services-API</h1>

<div align="center">

[English](./README-EN.md) | [ç®€ä½“ä¸­æ–‡](./README.md)

 <hr>
</div>
    
<div align="left">

ğŸš€ã€Œ**[Fast-Powerful-Whisper-AI-Services-API](https://github.com/Evil0ctal/Fast-Powerful-Whisper-AI-Services-API)** ã€çš„æ„¿æ™¯æ˜¯æ‰“é€ ä¸€ä¸ªå¼ºå¤§ä¸”å¼€ç®±å³ç”¨çš„ [Whisper](https://github.com/openai/whisper) æœåŠ¡ APIï¼Œä¸“ä¸ºé«˜æ€§èƒ½ã€é«˜æ‰©å±•æ€§å’Œåˆ†å¸ƒå¼å¤„ç†éœ€æ±‚è€Œè®¾è®¡ï¼Œå¹¶ä¸”ä»¥ç”Ÿäº§è€…æ¶ˆè´¹è€…æ¨¡å¼ä¸ºè®¾è®¡æ ¸å¿ƒæ‰“é€ ï¼Œç†æƒ³é€‚ç”¨äºéœ€è¦å¤§è§„æ¨¡ã€é«˜æ•ˆè‡ªåŠ¨è¯­éŸ³è¯†åˆ«çš„åœºæ™¯ã€‚è¯¥é¡¹ç›®åŸºäº OpenAI Whisper æ¨¡å‹ä»¥åŠæ¨ç†é€Ÿåº¦æ›´å¿«å¹¶ä¸”å‡†ç¡®åº¦è¿‘ä¼¼çš„ Faster Whisper æ¨¡å‹ï¼Œæ”¯æŒå¤šè¯­è¨€çš„é«˜è´¨é‡è¯­éŸ³è½¬å½•å’Œç¿»è¯‘ä»»åŠ¡ï¼Œå¹¶ä¸”å†…ç½®çš„çˆ¬è™«æ¨¡å—å¯ä»¥è½»æ¾å®ç°å¯¹æŠ–éŸ³å’ŒTikTokç­‰ç¤¾äº¤åª’ä½“å¹³å°çš„è§†é¢‘è¿›è¡Œå¤„ç†ï¼Œåªéœ€è¦è¾“å…¥ä¸€ä¸ªé“¾æ¥æ¥å£è½»æ¾åˆ›å»ºä»»åŠ¡ã€‚

æœ¬ç³»ç»Ÿé€šè¿‡å¼‚æ­¥æ¨¡å‹æ± æ–¹æ¡ˆå®ç°äº†é«˜æ•ˆçš„èµ„æºè°ƒåº¦ä¸ä»»åŠ¡ç®¡ç†ï¼Œå¹¶ä¸”å¼‚æ­¥æ¨¡å‹æ± æ”¯æŒä½¿ç”¨å¤šä¸ªGPUè¿›è¡Œå¹¶è¡Œè®¡ç®—ï¼Œæä¾›å®Œå…¨æœ¬åœ°åŒ–ã€é«˜æ‹“å±•æ€§ï¼Œä¸”å¯é çš„è§£å†³æ–¹æ¡ˆã€‚æ­¤å¤–ï¼Œé¡¹ç›®è®¡åˆ’å®ç°ä¸€å¥—çµæ´»çš„è‡ªå®šä¹‰ç»„ä»¶å’Œå·¥ä½œæµè®¾è®¡ï¼Œä½¿ç”¨æˆ·å¯ä»¥é€šè¿‡ JSON æ–‡ä»¶å®šä¹‰å¤æ‚çš„å¤šæ­¥éª¤ä»»åŠ¡æµï¼Œæˆ–é€šè¿‡ Python ç¼–å†™è‡ªå®šä¹‰ç»„ä»¶ï¼Œæ‰©å±•åŠŸèƒ½ã€‚å†…ç½®é«˜æ€§èƒ½çš„å¼‚æ­¥ HTTP æ¨¡å—ï¼Œå¼‚æ­¥æ–‡ä»¶IOæ¨¡å—ï¼Œå¼‚æ­¥æ•°æ®åº“æ¨¡å—ï¼Œç”¨æˆ·å¯ä»¥åˆ©ç”¨è¿™äº›æ¨¡å—ç¼–å†™è‡ªå·±çš„æœåŠ¡æˆ–ä»»åŠ¡å¤„ç†å™¨æ¥æ‹“å±•ä¸šåŠ¡ï¼Œæœªæ¥è®¡åˆ’ä¸ChatGPTç­‰LLM APIè¿›è¡Œæ¥å…¥ï¼Œå®ç°è‡ªåŠ¨è¯­éŸ³è¯†åˆ«åˆ°è‡ªç„¶è¯­è¨€å¤„ç†å’Œåˆ†æçš„çš„å®Œæ•´å·¥ä½œæµç¨‹ã€‚
    
</div>

## ğŸŒŸ é¡¹ç›®ç‰¹è‰²

* **å¼‚æ­¥è®¾è®¡** ï¼šåŸºäºPython 3.11çš„ asyncio å¼‚æ­¥ç‰¹æ€§ï¼Œæ‰€æœ‰æ¨¡å—éƒ½ä½¿ç”¨å¼‚æ­¥ç‰¹æ€§è¿›è¡Œç¼–å†™ï¼Œå®ç°è¯·æ±‚çš„é«˜æ•ˆå¤„ç†ï¼Œæå‡æ•´ä½“ç³»ç»Ÿçš„ç¨³å®šæ€§å’Œé«˜å¹¶å‘èƒ½åŠ›ã€‚
* **è‡ªå¸¦æ–‡æ¡£UI**ï¼šå¾—ç›ŠäºFastAPIè‡ªåŠ¨ç”Ÿæˆçš„OpenAPI JSONï¼Œæœ¬é¡¹ç›®è‡ªå¸¦ä¸€ä¸ªå¯äº¤äº’çš„Swagger UIç”¨äºåœ¨æµè§ˆå™¨ä¸­å¯è§†åŒ–çš„æµ‹è¯•æ¥å£ï¼Œå¹¶ä¸”æ¥å£Swagger UIä¸­å¸¦æœ‰è¯¦ç»†çš„ä¸­æ–‡+è‹±æ–‡åŒè¯­è¯´æ˜å’Œé»˜è®¤å‚æ•°è®¾ç½®ï¼Œç”¨æˆ·å¯ä»¥å¿«é€Ÿçš„ä¸Šæ‰‹æµ‹è¯•ã€‚
* **é«˜å‡†ç¡®ç‡**ï¼šä½¿ç”¨æœ€æ–°çš„`large-v3`æ¨¡å‹ç¡®ä¿è¾“å‡ºçš„å‡†ç¡®ç‡ï¼Œå¹¶ä¸”å¾—ç›ŠäºFaster Whisperçš„åŠ æŒï¼Œåœ¨ä¿è¯å‡†ç¡®ç‡çš„æƒ…å†µä¸‹å¯ä»¥æå¤§åœ°ç¼©çŸ­æ¨ç†æ‰€éœ€çš„æ—¶é—´ã€‚
* **åˆ†å¸ƒå¼éƒ¨ç½²**ï¼šæœ¬é¡¹ç›®å¯ä»¥ä»åŒä¸€ä¸ªæ•°æ®åº“ä¸­è·å–ä»»åŠ¡ä»¥åŠå­˜å‚¨ä»»åŠ¡ç»“æœï¼Œæœªæ¥è®¡åˆ’ä¸Kafkaæ— ç¼å¯¹æ¥ï¼Œå®ç°FastAPIä¸Kafkaçš„å®Œç¾äº¤å“ï¼šæ„å»ºå®æ—¶æ›´æ–°çš„æ™ºèƒ½Web API
* **å¼‚æ­¥æ¨¡å‹æ± ** ï¼šæœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ªé«˜æ•ˆçš„å¼‚æ­¥AIæ¨¡å‹æ± ï¼Œåœ¨çº¿ç¨‹å®‰å…¨çš„æƒ…å†µä¸‹æ”¯æŒ OpenAI Whisper å’Œ Faster Whisper æ¨¡å‹çš„å¤šå®ä¾‹å¹¶å‘å¤„ç†åœºæ™¯ï¼Œåœ¨æ”¯æŒCUDAåŠ é€Ÿä¸”æ‹¥æœ‰å¤šä¸ªGPUçš„åœºæ™¯ä¸­ï¼Œé€šè¿‡æ™ºèƒ½åŠ è½½æœºåˆ¶å¯ä»¥å°†å¤šä¸ªæ¨¡å‹æ™ºèƒ½çš„åŠ è½½åœ¨å¤šä¸ªGPUä¸Šï¼Œç„¶åæ¨¡å‹å®ä¾‹é—´è‡ªåŠ¨åˆ†é…ä»»åŠ¡ï¼Œç¡®ä¿ä»»åŠ¡å¤„ç†é€Ÿåº¦å’Œç³»ç»Ÿè´Ÿè½½å‡è¡¡ï¼Œä½†æ˜¯åœ¨å•ä¸€GPUåœºæ™¯ä¸‹æ— æ³•æä¾›å¹¶å‘åŠŸèƒ½ã€‚
* **å¼‚æ­¥æ•°æ®åº“**ï¼šæœ¬é¡¹ç›®æ”¯æŒä½¿ç”¨MySQLå’ŒSQLiteä½œä¸ºæ•°æ®åº“ï¼Œåœ¨æœ¬æœºè¿è¡Œæ—¶æ— éœ€å®‰è£…å’Œé…ç½®MySQLï¼Œä½¿ç”¨SQLiteå³å¯å¿«é€Ÿè¿è¡Œé¡¹ç›®ï¼Œå¦‚æœä½¿ç”¨MySQLåˆ™å¯ä»¥æ›´å¥½çš„é…åˆåˆ†å¸ƒå¼è®¡ç®—ï¼Œå¤šä¸ªèŠ‚ç‚¹ä½¿ç”¨åŒä¸€ä¸ªæ•°æ®åº“ä½œä¸ºä»»åŠ¡æºã€‚
* **å¼‚æ­¥ç½‘ç»œçˆ¬è™«**ï¼šæœ¬é¡¹ç›®å†…ç½®äº†å¤šä¸ªå¹³å°çš„æ•°æ®çˆ¬è™«æ¨¡å—ï¼Œå½“å‰æ”¯æŒ`æŠ–éŸ³`ã€`TikTok`ï¼Œç”¨æˆ·åªéœ€è¦è¾“å…¥å¯¹åº”çš„è§†é¢‘é“¾æ¥å³å¯å¿«é€Ÿçš„å¯¹åª’ä½“è¿›è¡Œè¯­éŸ³è¯†åˆ«ï¼Œå¹¶ä¸”æœªæ¥è®¡åˆ’æ”¯æŒæ›´å¤šç¤¾äº¤åª’ä½“å¹³å°ã€‚
* **å·¥ä½œæµä¸ç»„ä»¶åŒ–è®¾è®¡ï¼ˆå¾…å®ç°ï¼‰** ï¼šå›´ç»• Whisper è½¬å½•ä»»åŠ¡ï¼Œé¡¹ç›®æ”¯æŒé«˜åº¦è‡ªå®šä¹‰çš„å·¥ä½œæµç³»ç»Ÿã€‚ç”¨æˆ·å¯ä»¥é€šè¿‡ JSON æ–‡ä»¶å®šä¹‰ç»„ä»¶ã€ä»»åŠ¡ä¾èµ–å’Œæ‰§è¡Œé¡ºåºï¼Œç”šè‡³å¯ä»¥ä½¿ç”¨ Python ç¼–å†™è‡ªå®šä¹‰ç»„ä»¶ï¼Œçµæ´»æ‰©å±•ç³»ç»ŸåŠŸèƒ½ï¼Œè½»æ¾å®ç°å¤æ‚çš„å¤šæ­¥éª¤å¤„ç†æµç¨‹ã€‚
* **äº‹ä»¶é©±åŠ¨çš„æ™ºèƒ½å·¥ä½œæµï¼ˆå¾…å®ç°ï¼‰** ï¼šå·¥ä½œæµç³»ç»Ÿæ”¯æŒäº‹ä»¶è§¦å‘ï¼Œå¯ä»¥åŸºäºæ—¶é—´ã€æ‰‹åŠ¨è§¦å‘ï¼Œæˆ–ç”±çˆ¬è™«æ¨¡å—è‡ªåŠ¨è§¦å‘ã€‚ç›¸æ¯”å•ä¸€ä»»åŠ¡ï¼Œå·¥ä½œæµæ›´åŠ æ™ºèƒ½ï¼Œæ”¯æŒæ¡ä»¶åˆ†æ”¯ã€ä»»åŠ¡ä¾èµ–ã€åŠ¨æ€å‚æ•°ä¼ é€’å’Œé‡è¯•ç­–ç•¥ï¼Œä¸ºç”¨æˆ·æä¾›æ›´é«˜çš„è‡ªåŠ¨åŒ–å’Œå¯æ§æ€§ã€‚

## ğŸ’« é€‚ç”¨åœºæ™¯

* **åª’ä½“æ•°æ®å¤„ç†** ï¼šé€‚ç”¨äºéœ€è¦å¤§è§„æ¨¡è¯­éŸ³è½¬æ–‡æœ¬å¤„ç†çš„åœºæ™¯ï¼Œæ¯”å¦‚ç½‘ç»œæˆ–æœ¬åœ°çš„åª’ä½“æ–‡ä»¶è½¬å½•ï¼Œåˆ†æï¼Œç¿»è¯‘ï¼Œç”Ÿæˆå­—å¹•ç­‰åº”ç”¨ã€‚
* **è‡ªåŠ¨åŒ–å·¥ä½œæµ** ï¼šè™½ç„¶ç›®å‰é¡¹ç›®æœ¬èº«æ²¡æœ‰å®ç°å·¥ä½œæµï¼Œä½†æ˜¯å¯ä»¥é€šè¿‡APIäºå…¶ä»–å¹³å°çš„ä»»åŠ¡æµç³»ç»Ÿè¿›è¡Œæ¥å…¥ï¼Œé€šè¿‡äº‹ä»¶é©±åŠ¨çš„å·¥ä½œæµï¼Œè½»æ¾å®ç°å¤æ‚ä»»åŠ¡çš„è‡ªåŠ¨åŒ–æ‰§è¡Œï¼Œé€‚åˆéœ€è¦å¤šæ­¥éª¤å¤„ç†å’Œæ¡ä»¶æ§åˆ¶çš„ä¸šåŠ¡é€»è¾‘ã€‚
* **åŠ¨æ€æ•°æ®é‡‡é›†** ï¼šç»“åˆå¼‚æ­¥çˆ¬è™«æ¨¡å—ï¼Œç³»ç»Ÿå¯è‡ªåŠ¨é‡‡é›†å’Œå¤„ç†æ¥è‡ªç½‘ç»œçš„æ•°æ®ï¼Œå¹¶ä¸”å­˜å‚¨å¤„ç†å®Œæˆåçš„æ•°æ®ã€‚
* **åˆ©ç”¨åˆ†å¸ƒç®—åŠ›**ï¼šåœ¨å¤šä¸ªåˆ†å¸ƒçš„é›¶æ•£ç®—åŠ›ä¸‹ï¼Œå¯ä»¥ä½¿ç”¨ç½‘å…³çš„å½¢å¼å°†åˆ†æ•£çš„ç®—åŠ›è¿›è¡Œæœ‰æ•ˆåˆ©ç”¨ã€‚


## ğŸš© å·²å®ç°çš„åŠŸèƒ½ï¼š

- **åˆ›å»ºä»»åŠ¡ï¼š** æ”¯æŒä¸Šä¼ åª’ä½“æ–‡ä»¶ï¼ˆ`file_upload`ï¼‰æˆ–æŒ‡å®šåª’ä½“æ–‡ä»¶é“¾æ¥ï¼ˆ`file_url`ï¼‰ä½œä¸ºä»»åŠ¡çš„æ•°æ®æºï¼Œå¹¶ä¸”è®¾ç½®ä¸€ç³»åˆ—å‚æ•°æ›´åŠ ç»†ç²’çš„å¤„ç†ä»»åŠ¡ï¼Œè§ä¸‹æ–‡ã€‚
- **è®¾ç½®ä»»åŠ¡ç±»å‹ï¼š** ç”¨æˆ·å¯ä»¥é€šè¿‡ä¿®æ”¹ï¼ˆ`task_type`ï¼‰å‚æ•°è®¾ç½®ä»»åŠ¡ç±»å‹ï¼Œå½“å‰æ”¯æŒåª’ä½“æ–‡ä»¶è½¬æ–‡æœ¬ï¼ˆ`transcribe`ï¼‰æˆ–è‡ªåŠ¨ç¿»è¯‘ï¼ˆ`translate`ï¼‰
- **è®¾ç½®ä»»åŠ¡å¤„ç†ä¼˜å…ˆçº§ï¼š** ç”¨æˆ·å¯ä»¥é€šè¿‡ `priority` å‚æ•°æŒ‡å®šä»»åŠ¡ä¼˜å…ˆçº§ï¼Œç›®å‰æ”¯æŒä¸‰ç§ä¼˜å…ˆçº§ï¼ˆ`high`, `normal`, `low`ï¼‰
- **ä»»åŠ¡å›è°ƒé€šçŸ¥ï¼š** ç”¨æˆ·åœ¨åˆ›å»ºä»»åŠ¡æ—¶å¯ä»¥æŒ‡å®š `callback_url` ä½œä¸ºä»»åŠ¡å®Œæˆåçš„æ•°æ®æ¥æ”¶åœ°å€ï¼Œä»»åŠ¡å¤„ç†å®Œæˆåä¼šå‘ç›®æ ‡åœ°å€å‘é€ä¸€ä¸ªHTTP POSTè¯·æ±‚å°†ä»»åŠ¡çš„ç»“æœæ•°æ®ä¼ é€’åˆ°æŒ‡å®šæœåŠ¡å™¨ï¼Œå¹¶ä¸”å›è°ƒçŠ¶æ€ä¼šè¢«è®°å½•åœ¨æ•°æ®åº“ä¸­æ–¹ä¾¿å®¡æŸ¥ã€‚
- **å¤šå¹³å°æ”¯æŒï¼š** ç”¨æˆ·å¯ä»¥åœ¨å¯¹åº”æ¥å£ä¸­åˆ›å»ºæŠ–éŸ³ä»»åŠ¡ã€TikTokä»»åŠ¡ï¼Œä¹Ÿå¯ä»¥æ‰‹åŠ¨ä½¿ç”¨è§†é¢‘é“¾æ¥å¹¶ä¸”æ‰‹åŠ¨ä½¿ç”¨`platform`å‚æ•°æ ‡è®°å¹³å°åç§°ã€‚
- **è®¾ç½®Whisperå‚æ•°ï¼š** ç”¨æˆ·å¯ä»¥æ‰‹åŠ¨è®¾ç½®è§£ç å‚æ•°æ¥ä¿®æ”¹æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹ï¼Œå½“å‰æ”¯æŒå¤šç§å‚æ•°ï¼ˆ`language`ï¼Œ`temperature`, `compression_ratio_threshold`, `no_speech_threshold`, `condition_on_previous_text`, `initial_prompt`, `word_timestamps`, `prepend_punctuations`, `append_punctuations`, `clip_timestamps`, `hallucination_silence_threshold`ï¼‰
- **æŸ¥è¯¢ä»»åŠ¡**ï¼šç”¨æˆ·å¯ä»¥æ ¹æ®å¤šç§ç­›é€‰æ¡ä»¶æŸ¥è¯¢ä»»åŠ¡åˆ—è¡¨ï¼ŒåŒ…æ‹¬ä»»åŠ¡çŠ¶æ€ã€ä¼˜å…ˆçº§ã€åˆ›å»ºæ—¶é—´ã€è¯­è¨€ã€å¼•æ“åç§°ç­‰ä¿¡æ¯ï¼Œè¯¥æ¥å£é€‚ç”¨äºåˆ†é¡µæŸ¥è¯¢ï¼Œå¹¶ä¸”é€šè¿‡ limit å’Œ offset å‚æ•°æ§åˆ¶æ¯é¡µæ˜¾ç¤ºçš„è®°å½•æ•°ï¼Œæ”¯æŒå®¢æˆ·ç«¯é€é¡µåŠ è½½æ•°æ®ã€‚
- **åˆ é™¤ä»»åŠ¡**ï¼š ç”¨æˆ·å¯ä»¥æ ¹æ®ä»»åŠ¡IDåˆ é™¤ä»»åŠ¡ï¼Œåˆ é™¤åä»»åŠ¡æ•°æ®å°†è¢«æ°¸ä¹…åˆ é™¤ã€‚
- **è·å–ä»»åŠ¡ç»“æœ**ï¼šç”¨æˆ·å¯ä»¥æ ¹æ®ä»»åŠ¡IDè·å–æŒ‡å®šä»»åŠ¡çš„ç»“æœä¿¡æ¯ã€‚
- **æå–è§†é¢‘çš„éŸ³é¢‘**ï¼šè¿è¡Œç”¨æˆ·ä¸Šä¼ æ–‡ä»¶æ¥ä»è§†é¢‘æ–‡ä»¶ä¸­æå–éŸ³é¢‘ï¼Œæ”¯æŒè®¾ç½®é‡‡æ ·ç‡ï¼ˆ`sample_rate`ï¼‰ï¼Œä½æ·±åº¦ï¼ˆ`bit_depth`ï¼‰ï¼Œè¾“å‡ºæ ¼å¼ï¼ˆ`output_format`ï¼‰ã€‚
- **ç”Ÿæˆå­—å¹•æ–‡ä»¶**ï¼šç”¨æˆ·å¯ä»¥é€šè¿‡æŒ‡å®šçš„ä»»åŠ¡IDæ¥ç”ŸæˆæŒ‡å®šä»»åŠ¡çš„å­—å¹•ï¼Œå¹¶ä¸”æ”¯æŒæŒ‡å®šè¾“å‡ºæ ¼å¼ï¼ˆ`output_format`ï¼‰ï¼Œå½“å‰æ”¯æŒï¼ˆ`srt`ï¼‰ä»¥åŠï¼ˆ`vtt`ï¼‰ä½œä¸ºå­—å¹•æ–‡ä»¶æ ¼å¼ã€‚
- **åˆ›å»ºTikTokä»»åŠ¡**ï¼šç”¨æˆ·å¯ä»¥é€šè¿‡ TikTok è§†é¢‘é“¾æ¥çˆ¬å–è§†é¢‘å¹¶åˆ›å»ºä»»åŠ¡ã€‚
- **åˆ›å»ºæŠ–éŸ³ä»»åŠ¡**ï¼šç”¨æˆ·å¯ä»¥é€šè¿‡æŠ–éŸ³è§†é¢‘é“¾æ¥çˆ¬å–è§†é¢‘å¹¶åˆ›å»ºä»»åŠ¡ã€‚

## ğŸ“¸ é¡¹ç›®æˆªå›¾


![2024_07_56_AM.png](https://github.com/Evil0ctal/Fast-Powerful-Whisper-AI-Services-API/blob/main/github/screenshots/2024_07_56_AM.png?raw=true)

## ğŸš€ å¿«é€Ÿéƒ¨ç½²

1. **å…‹éš†æœ¬é¡¹ç›®**ï¼š ç¡®ä¿ä½ çš„ç”µè„‘ä¸Šæ­£ç¡®å®‰è£…äº†`git`ï¼Œç„¶åæ‰“å¼€ä½ ç”µè„‘ä¸Šçš„æ§åˆ¶å°æˆ–ç»ˆç«¯æ¥æ‰§è¡Œä¸‹æ–¹çš„å‘½ä»¤
    - ä¸‹è½½é¡¹ç›®æ–‡ä»¶ï¼š
        ```bash
        git clone https://github.com/Evil0ctal/Fast-Powerful-Whisper-AI-Services-API.git
        ```
2. **Python ç¯å¢ƒ**ï¼šæ¨èä½¿ç”¨Python ç‰ˆæœ¬ `3.12` æˆ–ç¡®ä¿ Python ç‰ˆæœ¬ >= `3.8`ã€‚
3. **å®‰è£… FFmpeg**ï¼šæœ¬é¡¹ç›®ä½¿ç”¨ [FFmpeg](https://www.ffmpeg.org/) ä½œä¸ºéŸ³è§†é¢‘ç¼–è§£ç å·¥å…·ï¼Œä½ å¯ä»¥æ ¹æ®ä½ çš„ç³»ç»Ÿç±»å‹æ¥æ‰§è¡Œä¸‹æ–¹å¯¹åº”çš„å‘½ä»¤æ¥å®‰è£…ã€‚
    - **Ubuntu or Debian ç³»ç»Ÿ**  
        ```bash
        sudo apt update && sudo apt install ffmpeg
        ```
    - **Arch Linux ç³»ç»Ÿ**
        ```bash
        sudo pacman -S ffmpeg
        ```
    - **MacOS ç³»ç»Ÿ (Homebrew)**
        ```bash
        brew install ffmpeg
        ```
    - **Windows ç³»ç»Ÿ (Chocolatey - æ–¹æ³•ä¸€)**
        ```bash
        choco install ffmpeg
        ```
    - **Windows ç³»ç»Ÿ (Scoop - æ–¹æ³•äºŒ)**
        ```bash
        scoop install ffmpeg
        ```
4. **å®‰è£… CUDA**ï¼šæœ¬é¡¹ç›®ä½¿ç”¨ [CUDA](https://developer.nvidia.com/cuda-toolkit) åˆ©ç”¨ GPU è¿›è¡Œæ¨ç†åŠ é€Ÿï¼Œå¦‚æœä½ æƒ³ä»…ä½¿ç”¨ CPU æ¥è¿›è¡Œæ¨ç†åˆ™å¯è·³è¿‡è¿™éƒ¨åˆ†ã€‚
    - è¯·æ ¹æ®ä½ çš„ç³»ç»Ÿä¸‹è½½å¹¶å®‰è£…å¯¹åº”ç‰ˆæœ¬çš„ Cuda-Toolkit
    - [https://developer.nvidia.com/cuda-downloads](https://developer.nvidia.com/cuda-downloads)
5. **å®‰è£…æ”¯æŒCUDAçš„PyTorch**: ç¡®ä¿æ­£ç¡®å®‰è£…äº†åŒ¹é…ä½ çš„GPUçš„CUDA Toolkitã€‚
    - ä½¿ç”¨æ§åˆ¶å°æˆ–ç»ˆç«¯æ‰§è¡Œä¸‹æ–¹çš„å‘½ä»¤ï¼š
        ```bash
        pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
        ```
6. **å®‰è£…é¡¹ç›®ä¾èµ–**: ç¡®ä¿ä½ åœ¨é¡¹ç›®çš„ç›®å½•ä¸­ï¼Œè¿™ä¸€æ­¥å°†æŠŠæ‰€éœ€è¦çš„ä¾èµ–åº“å®‰è£…åˆ°æœ¬åœ°ã€‚
    - ä½¿ç”¨æ§åˆ¶å°æˆ–ç»ˆç«¯æ‰§è¡Œä¸‹æ–¹çš„å‘½ä»¤ï¼š
        ```bash
        pip install -r requirements.txt
        ```
7. **ä¿®æ”¹é¡¹ç›®çš„é»˜è®¤é…ç½®**ï¼šæœ¬é¡¹ç›®çš„å¤§å¤šæ•°è®¾ç½®éƒ½æ˜¯å¯ä»¥ä¿®æ”¹çš„ï¼Œä½ å¯ä»¥åœ¨ä¸‹é¢çš„é“¾æ¥ä¸­æŸ¥çœ‹é»˜è®¤çš„é¡¹ç›®é…ç½®ï¼Œé»˜è®¤çš„é…ç½®æ˜¯ä¸ä¼šè‡ªåŠ¨é‡è½½é¡¹ç›®çš„ï¼Œä½ ä¹Ÿå¯ä»¥åœ¨é…ç½®ä¸­å¼€å¯è‡ªåŠ¨é‡è½½ï¼Œä¿®æ”¹é…ç½®æ–‡ä»¶åå»ºè®®é‡å¯ä¸€æ¬¡æœåŠ¡ã€‚
    - é»˜è®¤é…ç½®æ–‡ä»¶é“¾æ¥ï¼š
    - https://github.com/Evil0ctal/Fast-Powerful-Whisper-AI-Services-API/blob/main/config/settings.py
8. **å¯åŠ¨é¡¹ç›®**ï¼šç¡®ä¿ä½ åœ¨é¡¹ç›®çš„æ ¹ç›®å½•ä¸‹ã€‚
    - å¯åŠ¨APIï¼š
        ```bash
        python3 start.py
        ```
    - åœ¨æµè§ˆå™¨ä¸ŠæŸ¥çœ‹æ¥å£æ–‡æ¡£
    - é¡¹ç›®é»˜è®¤è¿è¡Œåœ¨ http://127.0.0.1/

## âš—ï¸ æŠ€æœ¯æ ˆ

* **[OpenAI Whisper](https://github.com/openai/whisper)** - è¯­éŸ³è¯†åˆ«æ¨¡å‹
* **[Faster Whisper](https://github.com/SYSTRAN/faster-whisper)** - æ›´å¿«é€Ÿçš„è¯­éŸ³è¯†åˆ«æ¨¡å‹
* **[ffmpeg](https://ffmpeg.org/)** - éŸ³è§†é¢‘æ ¼å¼è½¬æ¢
* **[torch](https://pytorch.org/)** - æ·±åº¦å­¦ä¹ æ¡†æ¶
* **[FastAPI](https://github.com/fastapi/fastapi)** - é«˜æ€§èƒ½ API æ¡†æ¶
* **[HTTPX](https://www.python-httpx.org/)** - å¼‚æ­¥ HTTP æ¡†æ¶
* **[aiofile](https://github.com/Tinche/aiofiles)** - å¼‚æ­¥æ–‡ä»¶æ“ä½œ
* **[aiosqlite](https://github.com/omnilib/aiosqlite)** - å¼‚æ­¥æ•°æ®åº“æ“ä½œ
* **[aiosmysql](https://github.com/aio-libs/aiomysql)** - å¼‚æ­¥æ•°æ®åº“æ“ä½œ
* **[moviepy](https://github.com/Zulko/moviepy)** - è§†é¢‘ç¼–è¾‘
* **[pydub](https://github.com/jiaaro/pydub)** - éŸ³é¢‘ç¼–è¾‘

## ğŸ—ƒï¸ é¡¹ç›®ç»“æ„
```
ğŸ“‚ Fast-Powerful-Whisper-AI-Services-API/
â”œâ”€â”€ ğŸ“ app/
â”‚   â”œâ”€â”€ ğŸ“ api/ -> API layer containing models and routes
â”‚   â”‚   â”œâ”€â”€ ğŸ“ models/
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“„ APIResponseModel.py -> Defines API response models
â”‚   â”‚   â”œâ”€â”€ ğŸ“ routers/
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ” health_check.py -> Health check endpoint
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ whisper_tasks.py -> Routes for Whisper tasks
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ”„ work_flows.py -> Routes for workflow management
â”‚   â”‚   â””â”€â”€ ğŸ“„ router.py -> Main router module
â”‚   â”œâ”€â”€ ğŸ•¸ï¸ crawlers/ -> Modules for web crawling
â”‚   â”‚   â”œâ”€â”€ ğŸ“ platforms/
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ douyin/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ› abogus.py -> (`ãƒ»Ï‰ãƒ»Â´) Whats This? 
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸš€ crawler.py -> Douyin data crawler
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“¡ endpoints.py -> API endpoints for Douyin crawler
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ§© models.py -> Models for Douyin data
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ğŸ› ï¸ utils.py -> Utility functions for Douyin crawler
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“˜ README.md -> Douyin module documentation
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ tiktok/
â”‚   â”‚   â”‚       â”œâ”€â”€ ğŸš€ crawler.py -> TikTok data crawler
â”‚   â”‚   â”‚       â”œâ”€â”€ ğŸ“¡ endpoints.py -> API endpoints for TikTok crawler
â”‚   â”‚   â”‚       â”œâ”€â”€ ğŸ§© models.py -> Models for TikTok data
â”‚   â”‚   â”‚       â””â”€â”€ ğŸ“˜ README.md -> TikTok module documentation
â”‚   â”œâ”€â”€ ğŸ’¾ database/ -> Database models and management
â”‚   â”‚   â”œâ”€â”€ ğŸ—„ï¸ DatabaseManager.py -> Handles database connections
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ TaskModels.py -> Task-related database models
â”‚   â”‚   â””â”€â”€ ğŸ“‚ WorkFlowModels.py -> Workflow-related database models
â”‚   â”œâ”€â”€ ğŸŒ http_client/ -> HTTP client setup
â”‚   â”‚   â”œâ”€â”€ âš™ï¸ AsyncHttpClient.py -> Asynchronous HTTP client
â”‚   â”‚   â””â”€â”€ â— HttpException.py -> Custom HTTP exceptions
â”‚   â”œâ”€â”€ ğŸ¤– model_pool/ -> Model pooling and management
â”‚   â”‚   â””â”€â”€ ğŸ§  AsyncModelPool.py -> Asynchronous model pool manager
â”‚   â”œâ”€â”€ ğŸ”„ processors/ -> Task and workflow processors
â”‚   â”‚   â”œâ”€â”€ ğŸ“‹ task_processor.py -> Processes Whisper tasks
â”‚   â”‚   â””â”€â”€ ğŸ› ï¸ workflow_processor.py -> Processes workflows
â”‚   â”œâ”€â”€ ğŸ›ï¸ services/ -> Service layer for API functions
â”‚   â”‚   â”œâ”€â”€ ğŸ“² callback_service.py -> Handles callbacks
â”‚   â”‚   â”œâ”€â”€ ğŸ”„ workflow_service.py -> Workflow handling services
â”‚   â”‚   â””â”€â”€ ğŸ—£ï¸ whisper_service.py -> Whisper model-related services
â”‚   â”œâ”€â”€ ğŸ§° utils/ -> Utility functions
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ file_utils.py -> File operations and management
â”‚   â”‚   â””â”€â”€ ğŸ” logging_utils.py -> Logging utilities
â”‚   â”œâ”€â”€ âš™ï¸ workflows/ -> Workflow components
â”‚   â”‚   â””â”€â”€ ğŸ§© components/
â”‚   â”‚       â”œâ”€â”€ ğŸ› ï¸ base_component.py -> Base workflow component
â”‚   â”‚       â”œâ”€â”€ ğŸ“„ component_a.py -> Custom workflow component A
â”‚   â”‚       â””â”€â”€ ğŸ“„ component_b.py -> Custom workflow component B
â”‚   â””â”€â”€ ğŸš€ main.py -> Application entry point
â”œâ”€â”€ âš™ï¸ config/
â”‚   â””â”€â”€ ğŸ› ï¸ settings.py -> Configuration file
â”œâ”€â”€ ğŸ“ temp_files/ -> Temporary files folder
â”‚   â””â”€â”€ ğŸ“‚ -> Default TEMP Files Folder
â”œâ”€â”€ ğŸ“ log_files/ -> Log files folder
â”‚   â””â”€â”€ ğŸ“‚ -> Default LOG Files Folder
â””â”€â”€ ğŸ“‚ WhisperServiceAPI.db -> Default SQLite DB File
â””â”€â”€ ğŸ“„ requirements.txt -> Python package requirements
â””â”€â”€ ğŸ“ start.py -> Run to start the API
```

## ğŸ› ï¸ ä½¿ç”¨æŒ‡å—

- åˆ‡æ¢åˆ°é¡¹ç›®ç›®å½•ï¼Œä½¿ç”¨ä¸‹é¢çš„å‘½ä»¤å¯åŠ¨APIæœåŠ¡ï¼š
- `python3 start.py`
- éšåä½ å¯ä»¥è®¿é—®`http://localhost`æ¥æŸ¥çœ‹æ¥å£æ–‡æ¡£ï¼Œå¹¶ä¸”åœ¨ç½‘é¡µä¸Šæµ‹è¯•ã€‚

## ğŸ± æ¥å£ä½¿ç”¨ç¤ºä¾‹ï¼ˆCURLæ ¼å¼ï¼‰

- æ·»åŠ ä¸€ä¸ªTikTokä»»åŠ¡

```curl
curl -X 'POST' \
  'http://127.0.0.1/api/tiktok/video_task' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/x-www-form-urlencoded' \
  -d 'priority=normal&prepend_punctuations=%22'\''%E2%80%9C%C2%BF(%5B%7B-&no_speech_threshold=0.6&clip_timestamps=0&url=https%3A%2F%2Fwww.tiktok.com%2F%40taylorswift%2Fvideo%2F7359655005701311786&word_timestamps=false&platform=tiktok&temperature=0.8%2C1.0&task_type=transcribe&callback_url=&hallucination_silence_threshold=0&language=&condition_on_previous_text=true&compression_ratio_threshold=1.8&append_punctuations=%22'\''.%E3%80%82%2C%EF%BC%8C!%EF%BC%81%3F%EF%BC%9F%3A%EF%BC%9A%E2%80%9D)%5D%7D%E3%80%81&initial_prompt='
```

- å“åº”

```json
{
  "code": 200,
  "router": "http://127.0.0.1/api/tiktok/video_task",
  "params": {
    "language": null,
    "temperature": [
      0.8,
      1
    ],
    "compression_ratio_threshold": 1.8,
    "no_speech_threshold": 0.6,
    "condition_on_previous_text": true,
    "initial_prompt": "",
    "word_timestamps": false,
    "prepend_punctuations": "\"'â€œÂ¿([{-",
    "append_punctuations": "\"'.ã€‚,ï¼Œ!ï¼?ï¼Ÿ:ï¼šâ€)]}ã€",
    "clip_timestamps": "0.0",
    "hallucination_silence_threshold": null,
    "task_type": "transcribe",
    "priority": "normal",
    "callback_url": ""
  },
  "data": {
    "id": 8,
    "status": "queued",
    "callback_url": "",
    "callback_status_code": null,
    "callback_message": null,
    "callback_time": null,
    "priority": "normal",
    "engine_name": "faster_whisper",
    "task_type": "transcribe",
    "created_at": "2024-11-07T06:31:57.894804",
    "updated_at": "2024-11-07T06:31:57.894804",
    "task_processing_time": null,
    "file_path": null,
    "file_url": "https://api.tiktokv.com/aweme/v1/play/?file_id=3146fc434e4d493c93b78566726b9310&is_play_url=1&item_id=7359655005701311786&line=0&signaturev3=dmlkZW9faWQ7ZmlsZV9pZDtpdGVtX2lkLjA3YTkzYjY0ZTliOWUzMzVmN2VhODgxMTMyMDljYTJk&source=FEED&vidc=useast5&video_id=v12044gd0000cohbuanog65ltpj9jdpg",
    "file_name": null,
    "file_size_bytes": null,
    "file_duration": null,
    "language": null,
    "platform": "tiktok",
    "decode_options": {
      "language": null,
      "temperature": [
        0.8,
        1
      ],
      "compression_ratio_threshold": 1.8,
      "no_speech_threshold": 0.6,
      "condition_on_previous_text": true,
      "initial_prompt": "",
      "word_timestamps": false,
      "prepend_punctuations": "\"'â€œÂ¿([{-",
      "append_punctuations": "\"'.ã€‚,ï¼Œ!ï¼?ï¼Ÿ:ï¼šâ€)]}ã€",
      "clip_timestamps": "0.0",
      "hallucination_silence_threshold": null
    },
    "error_message": null,
    "output_url": "http://127.0.0.1/api/whisper/tasks/result?task_id=8",
    "result": null
  }
}
```

**åœ¨è¯·æ±‚ä½“ä¸­åŒ…å«éŸ³é¢‘æˆ–è§†é¢‘æ–‡ä»¶ï¼ŒAPI å°†è¿”å›è½¬å½•çš„æ–‡æœ¬ç»“æœã€‚**

## ğŸ¦º æ€§èƒ½æµ‹è¯•

- æµ‹è¯•ç¯å¢ƒä¸ç¡¬ä»¶é…ç½®
  - CPU: 13th Gen Intel(R) Core(TM) i9-13950HX 24æ ¸ 32çº¿ç¨‹ @ 2.20 GHz
  - GPU: NVIDIA GeForce RTX 4060 Laptop GPU
  - å†…å­˜: 64GB
  - ç³»ç»Ÿ: Windows 11

> å•åˆ—æ¨¡å¼æµ‹è¯•

- æˆ‘ä»¬ä½¿ç”¨ `faster whisper` æ¨¡å‹ä½œä¸ºå¼•æ“ï¼Œç„¶åä½¿ç”¨ `CUDA` è¿›è¡ŒåŠ é€Ÿã€‚
- ä½¿ç”¨`large-v3`ä½œä¸ºæ¨ç†æ¨¡å‹ã€‚
- å¼‚æ­¥æ¨¡å‹æ± çš„æœ€å¤§å¹¶å‘æ•°`MAX_CONCURRENT_TASKS`è®¾ç½®ä¸º 1ã€‚
- ä½¿ç”¨ä¸€ä¸ªæ—¶é•¿39ç§’çš„çŸ­è§†é¢‘ä½œä¸ºæµ‹è¯•æ–‡ä»¶ï¼Œè¿ç»­å‘é€5ä¸ªè¯·æ±‚ï¼Œæ‰€æœ‰ä»»åŠ¡å…¨éƒ¨å®Œæˆçš„æ€»è€—æ—¶ä¸º 32 ç§’ã€‚

> å¹¶å‘æ¨¡å¼æµ‹è¯•

- å¾…æ·»åŠ ã€‚

## ğŸ“ ä»£åŠæ¸…å•

- å®Œå–„çˆ¬è™«æ¨¡å—ï¼Œè®¡åˆ’æ·»åŠ å¹¶æ”¯æŒæ›´å¤šå¹³å°ã€‚
- å®Œå–„ä»»åŠ¡æµç³»ç»Ÿï¼Œå®ç°ä¸€ä¸ªç”±äº‹ä»¶æˆ–æ—¶é—´é©±åŠ¨çš„è‡ªåŠ¨åŒ–å·¥ä½œæµç³»ç»Ÿã€‚
- æ·»åŠ LLMçš„æ”¯æŒï¼Œè½¬å½•å®Œæˆçš„æ–‡æœ¬å¯ä»¥ç›´æ¥ç”¨äºè¿›ä¸€æ­¥å¤„ç†ï¼Œå¦‚å†…å®¹æ‘˜è¦ã€è¯­ä¹‰åˆ†æç­‰ï¼Œé€‚åˆäºŒæ¬¡åˆ†ææˆ–æ–‡æœ¬æŒ–æ˜éœ€æ±‚ã€‚
- ä¼˜åŒ–æ•°æ®åº“ç»“æ„å’Œæ•°æ®åº“è®¾è®¡ï¼Œè®¡åˆ’å¯¹Redisè¿›è¡Œæ”¯æŒï¼Œå¹¶ä¸”è®¡åˆ’æ·»åŠ æ›´å¤šå­—æ®µï¼Œæ•°æ®åº“ä»¥åå¯ä»¥å­˜æ”¾æ›´å¤šæ•°æ®ã€‚
- æ·»åŠ éƒ¨ç½²è„šæœ¬ï¼Œç¼–å†™ä¸€ä¸ªä¸€é”®éƒ¨ç½²è„šæœ¬æ–¹ä¾¿ç”¨æˆ·ä½¿ç”¨bashå¿«é€Ÿéƒ¨ç½²æœ¬é¡¹ç›®ã€‚
- ä½¿ç”¨Dockerå®¹å™¨åŒ–é¡¹ç›®ï¼Œè®¡åˆ’æ·»åŠ å¯¹å®¹å™¨çš„æ”¯æŒï¼Œä»¥åŠè‡ªåŠ¨åŒ–çš„å®¹å™¨ç¼–è¯‘è„šæœ¬ã€‚

## ğŸ”§ é»˜è®¤é…ç½®æ–‡ä»¶

```python
import os
from typing import Optional
from dotenv import load_dotenv

# åŠ è½½ .env æ–‡ä»¶ | Load .env file
load_dotenv()


class Settings:

    # FastAPI è®¾ç½® | FastAPI settings
    class FastAPISettings:
        # é¡¹ç›®åç§° | Project name
        title: str = "Fast-Powerful-Whisper-AI-Services-API"
        # é¡¹ç›®æè¿° | Project description
        description: str = "An open source speech-to-text API that runs completely locally. The project is based on the OpenAI Whisper model and the faster inference Faster Whisper model, and implements an asynchronous model pool, using the asynchronous features of FastAPI for efficient packaging, supporting thread-safe asynchronous task queues, asynchronous file IO, asynchronous database IO, asynchronous web crawler modules, and more custom features."
        # é¡¹ç›®ç‰ˆæœ¬ | Project version
        version: str = "1.0.3"
        # Swagger æ–‡æ¡£ URL | Swagger docs URL
        docs_url: str = "/"
        # æ˜¯å¦å¼€å¯ debug æ¨¡å¼ | Whether to enable debug mode
        debug: bool = False
        # å½“æ£€æµ‹åˆ°é¡¹ç›®ä»£ç å˜åŠ¨æ—¶æ˜¯å¦è‡ªåŠ¨é‡è½½é¡¹ç›® | Whether to automatically reload the project when changes to the project code are detected
        reload_on_file_change: bool = os.getenv("RELOAD_ON_FILE_CHANGE", True)
        # FastAPI æœåŠ¡ IP | FastAPI service IP
        ip: str = "0.0.0.0"
        # FastAPI æœåŠ¡ç«¯å£ | FastAPI service port
        port: int = 80

    # æ•°æ®åº“è®¾ç½® | Database settings
    class DatabaseSettings:
        # é€‰æ‹©æ•°æ®åº“ç±»å‹ï¼Œæ”¯æŒ "sqlite" å’Œ "mysql" | Select the database type, support "sqlite" and "mysql"
        # "sqlite"ï¼šé€‚åˆå°è§„æ¨¡é¡¹ç›®å•æœºè¿è¡Œï¼Œæ— éœ€å®‰è£…æ•°æ®åº“ï¼Œç›´æ¥ä½¿ç”¨æ–‡ä»¶å­˜å‚¨æ•°æ® | "sqlite": Suitable for small-scale projects running on a single machine, no need to install a database, directly use file storage data
        # "mysql"ï¼šé€‚åˆå¤§è§„æ¨¡é¡¹ç›®åˆ†å¸ƒå¼éƒ¨ç½²ï¼Œéœ€è¦å®‰è£… MySQL æ•°æ®åº“ | "mysql": Suitable for large-scale projects distributed deployment, need to install MySQL database
        # å¦‚æœä½ é€‰æ‹© "mysql"ï¼Œè¯·ç¡®ä¿å®‰è£…äº† aiomysql | If you choose "mysql", please make sure aiomysql is installed
        # å¦‚æœä½ é€‰æ‹© "sqlite"ï¼Œè¯·ç¡®ä¿å®‰è£…äº† aiosqlite | If you choose "sqlite", please make sure aiosqlite is installed
        db_type: str = os.getenv("DB_TYPE", "sqlite")

        # SQLite æ•°æ®åº“è®¾ç½® | SQLite database settings
        # æ•°æ®åº“åå­— | Database name
        sqlite_db_name: str = os.getenv("sqlite_db_name", "WhisperServiceAPI.db")
        # æ•°æ®åº“ URL | Database URL
        sqlite_url: str = f"sqlite+aiosqlite:///{sqlite_db_name}"

        # MySQL æ•°æ®åº“è®¾ç½® | MySQL database settings
        # æ•°æ®åº“åå­— | Database name
        mysql_db_name: str = os.getenv("MYSQL_DB_NAME", "")
        # æ•°æ®åº“ç”¨æˆ·å | Database username
        mysql_username: str = os.getenv("MYSQL_USERNAME", "")
        # æ•°æ®åº“å¯†ç  | Database password
        mysql_password: str = os.getenv("MYSQL_PASSWORD", "")
        # æ•°æ®åº“åœ°å€ | Database host
        mysql_host: str = os.getenv("MYSQL_HOST", "")
        # æ•°æ®åº“ç«¯å£ | Database port
        mysql_port: int = 3306
        # æ•°æ®åº“ URL | Database URL
        mysql_url: str = f"mysql+aiomysql://{mysql_username}:{mysql_password}@{mysql_host}:{mysql_port}/{mysql_db_name}"

    # Whisper æœåŠ¡ç±»è®¾ç½® | Whisper service class settings
    class WhisperServiceSettings:
        # Whisper æœåŠ¡çš„æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°ï¼Œè®¾ç½®ä¸º 1 æ—¶ä¸ºå•ä»»åŠ¡æ¨¡å¼ | The maximum number of concurrent tasks for the Whisper service, set to 1 for single task mode
        # å¦‚æœä½ æœ‰å¤šä¸ª GPUï¼Œå¯ä»¥è®¾ç½®å¤§äº 1ï¼Œåœ¨å•ä¸€ GPU ä¸Šè¿è¡Œå¤šä¸ªä»»åŠ¡æ— æ³•ç¼©çŸ­ä»»åŠ¡æ—¶é—´ï¼Œä½†å¯ä»¥æé«˜ä»»åŠ¡å¹¶å‘åº¦ | If you have multiple GPUs, you can set it to more than 1. Running multiple tasks on a single GPU cannot shorten the task time, but can increase the task concurrency
        MAX_CONCURRENT_TASKS: int = 1
        # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€çš„æ—¶é—´é—´éš”ï¼ˆç§’ï¼‰ï¼Œå¦‚æœè®¾ç½®è¿‡å°å¯èƒ½ä¼šå¯¼è‡´æ•°æ®åº“æŸ¥è¯¢é¢‘ç¹ï¼Œè®¾ç½®è¿‡å¤§å¯èƒ½ä¼šå¯¼è‡´ä»»åŠ¡çŠ¶æ€æ›´æ–°ä¸åŠæ—¶ã€‚
        # Time interval for checking task status (seconds). If set too small, it may cause frequent database queries.
        TASK_STATUS_CHECK_INTERVAL: int = 3

    # OpenAI Whisper è®¾ç½® | OpenAI Whisper settings
    class OpenAIWhisperSettings:
        # æ¨¡å‹åç§° | Model name
        openai_whisper_model_name: str = "large-v3"
        # è®¾å¤‡åç§°ï¼Œå¦‚ "cpu" æˆ– "cuda", ä¸º None æ—¶è‡ªåŠ¨é€‰æ‹© | Device name, such as "cpu" or "cuda", automatically selected when None
        openai_whisper_device: Optional[str] = None
        # æ¨¡å‹ä¸‹è½½æ ¹ç›®å½• | Model download root directory
        openai_whisper_download_root: Optional[str] = None
        # æ˜¯å¦åœ¨å†…å­˜ä¸­åŠ è½½æ¨¡å‹ | Whether to load the model in memory
        openai_whisper_in_memory: bool = False

    # Faster Whisper è®¾ç½® | Faster Whisper settings
    class FasterWhisperSettings:
        # æ¨¡å‹åç§° | Model name
        faster_whisper_model_size_or_path: str = "large-v3"
        # è®¾å¤‡åç§°ï¼Œå¦‚ "cpu" æˆ– "cuda", ä¸º 'auto' æ—¶è‡ªåŠ¨é€‰æ‹© | Device name, such as "cpu" or "cuda", automatically selected when 'auto'
        faster_whisper_device: str = "auto"
        # è®¾å¤‡IDï¼Œå½“ faster_whisper_device ä¸º "cuda" æ—¶æœ‰æ•ˆ | Device ID, valid when faster_whisper_device is "cuda"
        faster_whisper_device_index: int = 0
        # æ¨¡å‹æ¨ç†è®¡ç®—ç±»å‹ | Model inference calculation type
        faster_whisper_compute_type: str = "float16"
        # æ¨¡å‹ä½¿ç”¨çš„CPUçº¿ç¨‹æ•°ï¼Œè®¾ç½®ä¸º 0 æ—¶ä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„CPUçº¿ç¨‹ | The number of CPU threads used by the model, set to 0 to use all available CPU threads
        faster_whisper_cpu_threads: int = 0
        # æ¨¡å‹workeræ•° | Model worker count
        faster_whisper_num_workers: int = 1
        # æ¨¡å‹ä¸‹è½½æ ¹ç›®å½• | Model download root directory
        faster_whisper_download_root: Optional[str] = None

    # å¼‚æ­¥æ¨¡å‹æ± è®¾ç½® | Asynchronous model pool settings
    class AsyncModelPoolSettings:
        # å¼•æ“åç§° | Engine name
        # ç›®å‰åªæ”¯æŒ "openai_whisper" å’Œ "faster_whisper" | Currently only supports "openai_whisper" and "faster_whisper"
        engine: str = "faster_whisper"

        # æœ€å°çš„æ¨¡å‹æ± å¤§å° | Minimum model pool size
        min_size: int = 1

        # æœ€å¤§çš„æ¨¡å‹æ± å¤§å°ï¼Œå¦‚æœä½ æ²¡æœ‰å¤šä¸ª GPUï¼Œå»ºè®®è®¾ç½®ä¸º 1 | Maximum model pool size, if you don't have multiple GPUs, it is recommended to set it to 1
        # å¦‚æœä½ æœ‰å¤šä¸ª GPUï¼Œå¯ä»¥è®¾ç½®å¤§äº 1ï¼Œç¨‹åºä¼šè‡ªåŠ¨ä¸ºæ¯ä¸ª GPU åˆ›å»ºä¸€ä¸ªæ¨¡å‹å®ä¾‹ | If you have multiple GPUs, you can set it to more than 1, and the program will automatically create a model instance for each GPU
        max_size: int = 1

        # æ¯ä¸ª GPU æœ€å¤šæ”¯æŒçš„å®ä¾‹æ•°é‡ï¼Œå¦‚æœä½ çš„ GPU å†…å­˜è¶³å¤Ÿå¤§ï¼Œå¯ä»¥è®¾ç½®å¤§äº 1 | The maximum number of instances supported by each GPU, if your GPU memory is large enough, you can set it to more than 1
        max_instances_per_gpu: int = 1

        # æ˜¯å¦åœ¨æ¨¡å‹æ± åˆå§‹åŒ–æ—¶ä»¥æœ€å¤§çš„æ¨¡å‹æ± å¤§å°åˆ›å»ºæ¨¡å‹å®ä¾‹ | Whether to create model instances with the maximum model pool size when the model pool is initialized
        init_with_max_pool_size: bool = True

    # æ–‡ä»¶è®¾ç½® | File settings
    class FileSettings:
        # æ˜¯å¦è‡ªåŠ¨åˆ é™¤ä¸´æ—¶æ–‡ä»¶ | Whether to automatically delete temporary files
        auto_delete: bool = True
        # æ˜¯å¦é™åˆ¶ä¸Šä¼ æ–‡ä»¶å¤§å° | Whether to limit the size of uploaded files
        limit_file_size: bool = True
        # æœ€å¤§ä¸Šä¼ æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰| Maximum upload file size (bytes)
        max_file_size: int = 2 * 1024 * 1024 * 1024
        # ä¸´æ—¶æ–‡ä»¶ç›®å½• | Temporary file directory
        temp_files_dir: str = "./temp_files"
        # æ˜¯å¦åœ¨å¤„ç†ååˆ é™¤ä¸´æ—¶æ–‡ä»¶ | Whether to delete temporary files after processing
        delete_temp_files_after_processing: bool = True
        # å…è®¸ä¿å­˜çš„æ–‡ä»¶ç±»å‹ï¼ŒåŠ å¼ºæœåŠ¡å™¨å®‰å…¨æ€§ï¼Œä¸ºç©ºåˆ—è¡¨æ—¶ä¸é™åˆ¶ | Allowed file types, enhance server security, no restrictions when the list is empty
        allowed_file_types: list = [
            # ï¼ˆFFmpeg æ”¯æŒçš„åª’ä½“æ–‡ä»¶ï¼‰| (FFmpeg supported media files)
            '.3g2', '.3gp', '.aac', '.ac3', '.aiff', '.alac', '.amr', '.ape', '.asf', '.avi', '.avs', '.cavs', '.dirac',
            '.dts', '.dv', '.eac3', '.f4v', '.flac', '.flv', '.g722', '.g723_1', '.g726', '.g729', '.gif', '.gsm',
            '.h261', '.h263', '.h264', '.hevc', '.jpeg', '.jpg', '.lpcm', '.m4a', '.m4v', '.mkv', '.mlp', '.mmf',
            '.mov', '.mp2', '.mp3', '.mp4', '.mpc', '.mpeg', '.mpg', '.oga', '.ogg', '.ogv', '.opus', '.png', '.rm',
            '.rmvb', '.rtsp', '.sbc', '.spx', '.svcd', '.swf', '.tak', '.thd', '.tta', '.vc1', '.vcd', '.vid', '.vob',
            '.wav', '.wma', '.wmv', '.wv', '.webm', '.yuv',
            # ï¼ˆå­—å¹•æ–‡ä»¶ï¼‰| (Subtitle files)
            '.srt', '.vtt',
        ]

    # æ—¥å¿—è®¾ç½® | Log settings
    class LogSettings:
        # æ—¥å¿—çº§åˆ« | Log level
        """
        CRITICAL = 50
        FATAL = CRITICAL
        ERROR = 40
        WARNING = 30
        WARN = WARNING
        INFO = 20
        DEBUG = 10
        NOTSET = 0
        """
        level: int = 10
        # æ—¥å¿—æ–‡ä»¶ç›®å½• | Log file directory
        log_dir: str = "./log_files"
        # æ—¥å¿—æ–‡ä»¶å‰ç¼€ | Log file prefix
        log_file_prefix: str = "app"
        # æ—¥å¿—æ–‡ä»¶ç¼–ç  | Log file encoding
        encoding: str = "utf-8"
        # æ—¥å¿—æ–‡ä»¶å¤‡ä»½æ•° | Log file backup count
        backup_count: int = 7

    # æŠ–éŸ³ API è®¾ç½® | Douyin API settings
    class DouyinAPISettings:
        # Douyin Web Cookie
        web_cookie: str = os.getenv("DOUYIN_WEB_COOKIE", "")
        # Proxy
        proxy: str = os.getenv("DOUYIN_PROXY", None)
```

## ğŸ›¡ï¸ è®¸å¯åè®®

æœ¬é¡¹ç›®åŸºäº [Apache2.0](LICENSE) å¼€æºã€‚

å•†ç”¨ä»¥åŠå®šåˆ¶åˆä½œï¼Œè¯·è”ç³» **Emailï¼ševil0ctal1985@gmail.com**

## ğŸ“¬ è”ç³»æ–¹å¼

æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Œæ¬¢è¿é€šè¿‡ [issue](https://github.com/Evil0ctal/Fast-Powerful-Whisper-AI-Services-API/issues) ä¸æˆ‘ä»¬è”ç³»ã€‚

## ğŸ§‘â€ğŸ’» è´¡çŒ®æŒ‡å—

éå¸¸æ¬¢è¿å¤§å®¶æå‡ºæ„è§å’Œå»ºè®®ï¼å¯ä»¥é€šè¿‡ GitHub issue ä¸æˆ‘ä»¬è”ç³»ï¼Œå¦‚æœå¸Œæœ›è´¡çŒ®ä»£ç ï¼Œè¯· fork é¡¹ç›®å¹¶æäº¤ pull requestã€‚æˆ‘ä»¬æœŸå¾…ä½ çš„åŠ å…¥ï¼ğŸ’ª